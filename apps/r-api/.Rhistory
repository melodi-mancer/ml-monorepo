Profile1_new[, grep("new_", colnames(Profile1_new))]
Profile1_new <- Profile1_new[, grep("new_", colnames(Profile1_new))]
# Subset the new columns that contain "new_"
Profile1_new <- Profile1_new[, grep("new_", colnames(Profile1_new))]
Profile1_new
{
F3_factor_analysis_varimax <- function(df1) {
# keep only these columns as defined in required_audio_features
# required_audio_features is defined under
component_names <- names(required_audio_features)
# keep only columns that exist as names in component_names
# component_names is defined under #Reference models for the API requests
# Match column names case-insensitively
matched_cols <- colnames(df1)[tolower(colnames(df1)) %in% tolower(component_names)]
# Convert matched column names to lowercase in the data frame
colnames(df1)[tolower(colnames(df1)) %in% tolower(component_names)] <- tolower(matched_cols)
# Subset the data frame using the matched column names
df1 <- df1[, tolower(component_names), drop = FALSE]
# Create correlation matrix
CORClusters1 <- cor(df1, use = "complete.obs")
# Perform factor analysis
# varimax: to simplify the structure of the loadings matrix
# aims to make the loadings for each variable either very high or very low
# in a single factor while keeping them close to zero in all other factors
# only produce the recommended number of factors
nfact <- fa.parallel(CORClusters1, n.obs = nrow(Clusters1), plot = FALSE)$nfact
PCA1 <- principal(CORClusters1, nfactors = nfact, rotate = "varimax", scores = TRUE)
# Convert loadings to a data frame
Profile1 <- PCA1$loadings
# Cut off anything below "Valence" row
Profile1 <- Profile1[1:which(trimws(rownames(PCA1$loadings)) == "valence"), , drop = FALSE]
Profile1 <- as.data.frame(Profile1)
# Apply the transformation to all columns of Profile1
Profile1[] <- apply(Profile1, 2, function(x) {
ifelse(x < -0.39, -100,    #-100 for negative + 'significant' correlation
ifelse(x > 0.39, 100, 0))  # 100 for positive + 'significant' correlation
})
# Run Summary table function to get profile values as table
summary_table <- F2_summary_table(df1)
summary_table <- summary_table[, c("component", "q1", "q3")]
mutate_profile1 <- function(value, q1, q3) {
ifelse(value == 0, NA_real_,
ifelse(value == -100, q1,
ifelse(value == 100, q3, value)))
}
# Apply the mutate_profile1 function to each column in Profile1
Profile1_new <- Profile1
for (col in colnames(Profile1)) {
Profile1_new[[paste0("new_", col)]] <- mapply(mutate_profile1, Profile1[[col]],
MoreArgs = list(q1 = summary_table$q1, q3 = summary_table$q3))
}
return(list(PCA1 = PCA1, profile = Profile1_new))
}
}
{
F3_factor_analysis_varimax <- function(df1) {
component_names <- names(required_audio_features)
df1 <- df1 %>% select(one_of(component_names))
Clusters1 <- df1[, component_names]
CORClusters1 <- cor(Clusters1, use = "complete.obs")
FA <- fa.parallel(CORClusters1, n.obs = nrow(Clusters1), plot=FALSE)
PCA1 <- principal(CORClusters1, nfactors = FA$nfact, rotate = "varimax", scores = TRUE)
Profile1 <- PCA1$loadings
Profile1 <- Profile1[1:which(trimws(rownames(PCA1$loadings)) == "valence"), , drop = FALSE]
Profile1 <- as.data.frame(Profile1)
Profile1 <- Profile1 %>%
mutate_all(~ case_when(
. < -0.39 ~ -100, #-100 for negative + 'significant' correlation
. > 0.39 ~ 100, #100 for postive + 'significant' correlation
TRUE ~ 0 #0 for 'non-significant' correlation
))
result <- F2_summary_table(df1)
summary_table <- result
summary_table <- summary_table %>%
select(component, q1, q3)
mutate_profile1 <- function(value, q1, q3) {
case_when(
value == 0 ~ NA_real_,
value == -100 ~ q1,
value == 100 ~ q3,
TRUE ~ value
)
}
#
Profile1 <- Profile1 %>%
mutate(across(everything(), ~ mutate_profile1(.x, summary_table$q1, summary_table$q3), .names = "new_{.col}"))
Profile1 <- Profile1 %>%
select(contains("new_"))
return(list(PCA1 = PCA1, profile = Profile1))
}
}
F3_1_factor_analysis_varimax <- function(df1) {
# keep only these columns as defined in required_audio_features
# required_audio_features is defined under
component_names <- names(required_audio_features)
# keep only columns that exist as names in component_names
# component_names is defined under #Reference models for the API requests
# Match column names case-insensitively
matched_cols <- colnames(df1)[tolower(colnames(df1)) %in% tolower(component_names)]
# Convert matched column names to lowercase in the data frame
colnames(df1)[tolower(colnames(df1)) %in% tolower(component_names)] <- tolower(matched_cols)
# Subset the data frame using the matched column names
df1 <- df1[, tolower(component_names), drop = FALSE]
# Create correlation matrix
CORClusters1 <- cor(df1, use = "complete.obs")
# Perform factor analysis
# varimax: to simplify the structure of the loadings matrix
# aims to make the loadings for each variable either very high or very low
# in a single factor while keeping them close to zero in all other factors
# only produce the recommended number of factors
nfact <- fa.parallel(CORClusters1, n.obs = nrow(Clusters1), plot = FALSE)$nfact
PCA1 <- principal(CORClusters1, nfactors = nfact, rotate = "varimax", scores = TRUE)
# Convert loadings to a data frame
Profile1 <- PCA1$loadings
# Cut off anything below "Valence" row
Profile1 <- Profile1[1:which(trimws(rownames(PCA1$loadings)) == "valence"), , drop = FALSE]
Profile1 <- as.data.frame(Profile1)
# Apply the transformation to all columns of Profile1
Profile1[] <- apply(Profile1, 2, function(x) {
ifelse(x < -0.39, -100,    #-100 for negative + 'significant' correlation
ifelse(x > 0.39, 100, 0))  # 100 for positive + 'significant' correlation
})
# Run Summary table function to get profile values as table
summary_table <- F2_summary_table(df1)
summary_table <- summary_table[, c("component", "q1", "q3")]
mutate_profile1 <- function(value, q1, q3) {
ifelse(value == 0, NA_real_,
ifelse(value == -100, q1,
ifelse(value == 100, q3, value)))
}
# Apply the mutate_profile1 function to each column in Profile1
Profile1_new <- Profile1
for (col in colnames(Profile1)) {
Profile1_new[[paste0("new_", col)]] <- mapply(mutate_profile1, Profile1[[col]],
MoreArgs = list(q1 = summary_table$q1, q3 = summary_table$q3))
}
return(list(PCA1 = PCA1, profile = Profile1_new))
}
F3_factor_analysis_varimax(json_sample_nocap)
F3_1_factor_analysis_varimax(json_sample_nocap)
{
F3_1_factor_analysis_varimax <- function(df1) {
# keep only these columns as defined in required_audio_features
# required_audio_features is defined under
component_names <- names(required_audio_features)
# keep only columns that exist as names in component_names
# component_names is defined under #Reference models for the API requests
# Match column names case-insensitively
matched_cols <- colnames(df1)[tolower(colnames(df1)) %in% tolower(component_names)]
# Convert matched column names to lowercase in the data frame
colnames(df1)[tolower(colnames(df1)) %in% tolower(component_names)] <- tolower(matched_cols)
# Subset the data frame using the matched column names
df1 <- df1[, tolower(component_names), drop = FALSE]
# Create correlation matrix
CORClusters1 <- cor(df1, use = "complete.obs")
# Perform factor analysis
# varimax: to simplify the structure of the loadings matrix
# aims to make the loadings for each variable either very high or very low
# in a single factor while keeping them close to zero in all other factors
# only produce the recommended number of factors
nfact <- fa.parallel(CORClusters1, n.obs = nrow(Clusters1), plot = FALSE)$nfact
PCA1 <- principal(CORClusters1, nfactors = nfact, rotate = "varimax", scores = TRUE)
# Convert loadings to a data frame
Profile1 <- PCA1$loadings
# Cut off anything below "Valence" row
Profile1 <- Profile1[1:which(trimws(rownames(PCA1$loadings)) == "valence"), , drop = FALSE]
Profile1 <- as.data.frame(Profile1)
# Apply the transformation to all columns of Profile1
Profile1[] <- apply(Profile1, 2, function(x) {
ifelse(x < -0.39, -100,    #-100 for negative + 'significant' correlation
ifelse(x > 0.39, 100, 0))  # 100 for positive + 'significant' correlation
})
# Run Summary table function to get profile values as table
summary_table <- F2_summary_table(df1)
summary_table <- summary_table[, c("component", "q1", "q3")]
mutate_profile1 <- function(value, q1, q3) {
ifelse(value == 0, NA_real_,
ifelse(value == -100, q1,
ifelse(value == 100, q3, value)))
}
# Apply the mutate_profile1 function to each column in Profile1
Profile1_new <- Profile1
for (col in colnames(Profile1)) {
Profile1_new[[paste0("new_", col)]] <- mapply(mutate_profile1, Profile1[[col]],
MoreArgs = list(q1 = summary_table$q1, q3 = summary_table$q3))
}
return(list(PCA1 = PCA1, profile = Profile1_new))
}
}
F3_1_factor_analysis_varimax(json_sample)
F3_factor_analysis_varimax(json_sample_nocap)
# F3_1
{
F3_1_factor_analysis_varimax <- function(df1) {
# keep only these columns as defined in required_audio_features
# required_audio_features is defined under
component_names <- names(required_audio_features)
# keep only columns that exist as names in component_names
# component_names is defined under #Reference models for the API requests
# Match column names case-insensitively
matched_cols <- colnames(df1)[tolower(colnames(df1)) %in% tolower(component_names)]
# Convert matched column names to lowercase in the data frame
colnames(df1)[tolower(colnames(df1)) %in% tolower(component_names)] <- tolower(matched_cols)
# Subset the data frame using the matched column names
df1 <- df1[, tolower(component_names), drop = FALSE]
# Create correlation matrix
CORClusters1 <- cor(df1, use = "complete.obs")
# Perform factor analysis
# varimax: to simplify the structure of the loadings matrix
# aims to make the loadings for each variable either very high or very low
# in a single factor while keeping them close to zero in all other factors
# only produce the recommended number of factors
nfact <- fa.parallel(CORClusters1, n.obs = nrow(Clusters1), plot = FALSE)$nfact
PCA1 <- principal(CORClusters1, nfactors = nfact, rotate = "varimax", scores = TRUE)
# Convert loadings to a data frame
Profile1 <- PCA1$loadings
# Cut off anything below "Valence" row
Profile1 <- Profile1[1:which(trimws(rownames(PCA1$loadings)) == "valence"), , drop = FALSE]
Profile1 <- as.data.frame(Profile1)
# Apply the transformation to all columns of Profile1
Profile1[] <- apply(Profile1, 2, function(x) {
ifelse(x < -0.39, -100,    #-100 for negative + 'significant' correlation
ifelse(x > 0.39, 100, 0))  # 100 for positive + 'significant' correlation
})
# Run Summary table function to get profile values as table
summary_table <- F2_summary_table(df1)
summary_table <- summary_table[, c("component", "q1", "q3")]
mutate_profile1 <- function(value, q1, q3) {
ifelse(value == 0, NA_real_,
ifelse(value == -100, q1,
ifelse(value == 100, q3, value)))
}
# Apply the mutate_profile1 function to each column in Profile1
Profile1_new <- Profile1
for (col in colnames(Profile1)) {
Profile1_new[[paste0("new_", col)]] <- mapply(mutate_profile1, Profile1[[col]],
MoreArgs = list(q1 = summary_table$q1, q3 = summary_table$q3))
}
# Subset the new columns that contain "new_"
Profile1_new <- Profile1_new[, grep("new_", colnames(Profile1_new))]
return(list(PCA1 = PCA1, profile = Profile1_new))
}
}
F3_1_factor_analysis_varimax(json_sample)
# Benchmark time
{
results <- microbenchmark(
function1 = F3_factor_analysis_varimax(json_sample),
function2 = F3_1_factor_analysis_varimax(json_sample),
times = 100L,
control = list(warmup = 10L)
)
# Print the results
print(results)
# Plot the results (optional)
plot(results)
}
function1 = F3_factor_analysis_varimax(json_sample)
# Benchmark time
{
results <- microbenchmark(
function1 = F3_factor_analysis_varimax(json_sample_nocap),
function2 = F3_1_factor_analysis_varimax(json_sample_nocap),
times = 100L,
control = list(warmup = 10L)
)
# Print the results
print(results)
# Plot the results (optional)
plot(results)
}
F3_1_factor_analysis_varimax(json_sample)
# Packages
{
library(microbenchmark)
library(psych)
library(jsonlite)
library(tidyverse)
}
#Reference models for the API requests
{
required_audio_features <- list(
acousticness = 0,
danceability = 0,
liveness = 0,
instrumentalness = 0,
energy = 0,
loudness = 0,
speechiness = 0,
tempo = 0,
valence = 0
)
required_track_features <- list(
trackId = 0,
acousticness = 0,
danceability = 0,
liveness = 0,
instrumentalness = 0,
energy = 0,
loudness = 0,
speechiness = 0,
tempo = 0,
valence = 0
)
required_endpoint3 <- list(
profile = list(
acousticness = 0,
danceability = 0,
liveness = 0,
instrumentalness = 0,
energy = 0,
loudness = 0,
speechiness = 0,
tempo = 0,
valence = 0
),
tracks = list(
list(
trackId = 0,
acousticness = 0,
danceability = 0,
liveness = 0,
instrumentalness = 0,
energy = 0,
loudness = 0,
speechiness = 0,
tempo = 0,
valence = 0
)
)
)
}
{
json_sample <- fromJSON("output.json")
json_sample_cap <- json_sample[,
c("Acousticness",
"Danceability",
"Liveness",
"Instrumentalness",
"Energy",
"Loudness",
"Speechiness",
"Tempo",
"Valence")]
colnames(json_sample) <- tolower(colnames(json_sample))
json_sample_nocap <- json_sample[,
c("acousticness",
"danceability",
"liveness",
"instrumentalness",
"energy",
"loudness",
"speechiness",
"tempo",
"valence")]
}
F3_1_factor_analysis_varimax(json_sample)
# F3_1
{
F3_1_factor_analysis_varimax <- function(df1) {
# keep only these columns as defined in required_audio_features
# required_audio_features is defined under
component_names <- names(required_audio_features)
# keep only columns that exist as names in component_names
# component_names is defined under #Reference models for the API requests
# Match column names case-insensitively
matched_cols <- colnames(df1)[tolower(colnames(df1)) %in% tolower(component_names)]
# Convert matched column names to lowercase in the data frame
colnames(df1)[tolower(colnames(df1)) %in% tolower(component_names)] <- tolower(matched_cols)
# Subset the data frame using the matched column names
df1 <- df1[, tolower(component_names), drop = FALSE]
# Create correlation matrix
CORClusters1 <- cor(df1, use = "complete.obs")
# Perform factor analysis
# varimax: to simplify the structure of the loadings matrix
# aims to make the loadings for each variable either very high or very low
# in a single factor while keeping them close to zero in all other factors
# only produce the recommended number of factors
nfact <- fa.parallel(CORClusters1, n.obs = nrow(Clusters1), plot = FALSE)$nfact
PCA1 <- principal(CORClusters1, nfactors = nfact, rotate = "varimax", scores = TRUE)
# Convert loadings to a data frame
Profile1 <- PCA1$loadings
# Cut off anything below "Valence" row
Profile1 <- Profile1[1:which(trimws(rownames(PCA1$loadings)) == "valence"), , drop = FALSE]
Profile1 <- as.data.frame(Profile1)
# Apply the transformation to all columns of Profile1
Profile1[] <- apply(Profile1, 2, function(x) {
ifelse(x < -0.39, -100,    #-100 for negative + 'significant' correlation
ifelse(x > 0.39, 100, 0))  # 100 for positive + 'significant' correlation
})
# Run Summary table function to get profile values as table
summary_table <- F2_summary_table(df1)
summary_table <- summary_table[, c("component", "q1", "q3")]
mutate_profile1 <- function(value, q1, q3) {
ifelse(value == 0, NA_real_,
ifelse(value == -100, q1,
ifelse(value == 100, q3, value)))
}
# Apply the mutate_profile1 function to each column in Profile1
Profile1_new <- Profile1
for (col in colnames(Profile1)) {
Profile1_new[[paste0("new_", col)]] <- mapply(mutate_profile1, Profile1[[col]],
MoreArgs = list(q1 = summary_table$q1, q3 = summary_table$q3))
}
# Subset the new columns that contain "new_"
Profile1_new <- Profile1_new[, grep("new_", colnames(Profile1_new))]
return(list(profile = Profile1_new))
}
}
F3_1_factor_analysis_varimax(json_sample)
nfact <- fa.parallel(CORClusters1, n.obs = nrow(Clusters1), plot = FALSE)$nfact
nfact <- suppressMessages(fa.parallel(CORClusters1, n.obs = nrow(Clusters1), plot = FALSE)$nfact)
nfact <- suppressWarnings(fa.parallel(CORClusters1, n.obs = nrow(Clusters1), plot = FALSE)$nfact)
?fa.parallel
capture.output(fa.parallel(CORClusters1, n.obs = nrow(Clusters1), plot = FALSE))
nfact <- capture.output(fa.parallel(CORClusters1, n.obs = nrow(Clusters1), plot = FALSE))
as.numeric(sub(".*suggests that the number of factors = ([0-9]+).*", "\\1", nfact))
nfact
nfact <- capture.output(fa.parallel(CORClusters1, n.obs = nrow(Clusters1), plot = FALSE))
# F3_1
{
F3_1_factor_analysis_varimax <- function(df1) {
# keep only these columns as defined in required_audio_features
# required_audio_features is defined under
component_names <- names(required_audio_features)
# keep only columns that exist as names in component_names
# component_names is defined under #Reference models for the API requests
# Match column names case-insensitively
matched_cols <- colnames(df1)[tolower(colnames(df1)) %in% tolower(component_names)]
# Convert matched column names to lowercase in the data frame
colnames(df1)[tolower(colnames(df1)) %in% tolower(component_names)] <- tolower(matched_cols)
# Subset the data frame using the matched column names
df1 <- df1[, tolower(component_names), drop = FALSE]
# Create correlation matrix
CORClusters1 <- cor(df1, use = "complete.obs")
# Perform factor analysis
# varimax: to simplify the structure of the loadings matrix
# aims to make the loadings for each variable either very high or very low
# in a single factor while keeping them close to zero in all other factors
# only produce the recommended number of factors
nfact <- fa.parallel(CORClusters1, n.obs = nrow(Clusters1), plot = FALSE)$nfact
PCA1 <- principal(CORClusters1, nfactors = nfact, rotate = "varimax", scores = TRUE)
# Convert loadings to a data frame
Profile1 <- PCA1$loadings
# Cut off anything below "Valence" row
Profile1 <- Profile1[1:which(trimws(rownames(PCA1$loadings)) == "valence"), , drop = FALSE]
Profile1 <- as.data.frame(Profile1)
# Apply the transformation to all columns of Profile1
Profile1[] <- apply(Profile1, 2, function(x) {
ifelse(x < -0.39, -100,    #-100 for negative + 'significant' correlation
ifelse(x > 0.39, 100, 0))  # 100 for positive + 'significant' correlation
})
# Run Summary table function to get profile values as table
summary_table <- F2_summary_table(df1)
summary_table <- summary_table[, c("component", "q1", "q3")]
mutate_profile1 <- function(value, q1, q3) {
ifelse(value == 0, NA_real_,
ifelse(value == -100, q1,
ifelse(value == 100, q3, value)))
}
# Apply the mutate_profile1 function to each column in Profile1
Profile1_new <- Profile1
for (col in colnames(Profile1)) {
Profile1_new[[paste0("new_", col)]] <- mapply(mutate_profile1, Profile1[[col]],
MoreArgs = list(q1 = summary_table$q1, q3 = summary_table$q3))
}
# Subset the new columns that contain "new_"
Profile1_new <- Profile1_new[, grep("new_", colnames(Profile1_new))]
return(list(profile = Profile1_new))
}
}
F3_1_factor_analysis_varimax(json_sample)
{
results <- microbenchmark(
function1 = F3_factor_analysis_varimax(json_sample_nocap),
function2 = F3_1_factor_analysis_varimax(json_sample_nocap),
times = 100L,
control = list(warmup = 10L)
)
# Print the results
print(results)
# Plot the results (optional)
plot(results)
}
plumber::plumb(file='api_definition.R')$run()
plumb(file='api_definition.R')$run()
fromJSON("output.json")
json_sample <- fromJSON("output.json")
json_sample_cap <- json_sample[,
c("Acousticness",
"Danceability",
"Liveness",
"Instrumentalness",
"Energy",
"Loudness",
"Speechiness",
"Tempo",
"Valence")]
colnames(json_sample) <- tolower(colnames(json_sample))
json_sample_nocap <- json_sample[,
c("acousticness",
"danceability",
"liveness",
"instrumentalness",
"energy",
"loudness",
"speechiness",
"tempo",
"valence")]
toJSON(json_sample_nocap)
plumb(file='api_definition.R')$run()
install.packages(faucet)
